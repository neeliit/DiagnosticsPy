{"cells":[{"metadata":{"_cell_guid":"70c80082-d034-4fcf-ab71-b0249146c904","_uuid":"20b1a12fef056e269f5eb57f61d89445d3853b46"},"cell_type":"markdown","source":"# So, You Have a Diagnostic Test Result","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"5dc6a44f-1d7c-43fb-8a59-38a7f31fdcec","_uuid":"de37bdf84595d7c3357b37b82528fa65eb36d4d3"},"cell_type":"markdown","source":"### A kernel exploring the how, what and why of diagnostic testing","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"018191f5-1873-4dd9-920a-b6e645d21208","_uuid":"fe11ba85189471e88261ec14f8bbb6daa7f954a9"},"cell_type":"markdown","source":"*Rob Harrand, 27th Feb 2018*","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"4fd73633-b201-4d01-8d10-7b116125abfb","_uuid":"cdee6595773adb42b01732d5a50c4c54a8c5a9b2"},"cell_type":"markdown","source":"Datasets used in this kernel,\n\n- [Pima Indians Diabetes Database](https://www.kaggle.com/uciml/pima-indians-diabetes-database)\n- [Indian Liver Patient Records](https://www.kaggle.com/uciml/indian-liver-patient-records)\n- [Breast Cancer Wisconsin Diagnostic Dataset](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)\n- [Health Analytics](https://www.kaggle.com/rajanand/key-indicators-of-annual-health-survey)\n- [Health Nutrition and Population Statistics](https://www.kaggle.com/theworldbank/health-nutrition-and-population-statistics)\n","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"4e102b4b-85aa-4060-8ea0-18221e8bb488","_uuid":"8f8c658c13cb87604430016291a896bc5dab9ed7"},"cell_type":"markdown","source":"### Contents\n\n- [Introduction](#Introduction)\n- [Medical Testing](#MedicalTesting)\n- [Developing a Diagnostic Test](#DevelopingaDiagnosticTest)\n- [Test development is done?](#Testdevelopmentisdone?)\n- [Confidence Intervals](#ConfidenceIntervals)\n- [Enter Rev. Bayes](#EnterRevBayes)\n- [The Problem with Sensitivity and Specificity: An Example](#TheproblemwithsensitivityandspecificityAnexample)\n- [Context Matters - An Example](#ContextMattersAnExample)\n- [Belief Elicitation](#BeliefElicitation)\n- [From Prior to Posterior Probabilities](#FromPriortoPosteriorProbabilities)\n- [Treatment Thresholds](#TreatmentThresholds)\n- [Use In The Real World](#Useintherealworld)\n- [Closing Thoughts](#ClosingThoughts)\n- [References](#References)","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"613cc676-ea47-4d1a-84db-73c5db1bf5d2","_uuid":"a54f616bad131a9cc7a29b9ac4221496146b63f3"},"cell_type":"markdown","source":"<a id='Introduction'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"63285947-23f9-49fe-b3ba-b097aaeedfd0","_uuid":"cb976295a9aea9c1b209932b1df4224c79b93822"},"cell_type":"markdown","source":"### Introduction","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"06d12c53-ddae-4b19-b99e-54eeb10c6d10","_uuid":"8f2db6b2613d5556cadbbd8f52e920a813a82561"},"cell_type":"markdown","source":"A number of year ago, a close relative of mine was due the results of a diagnostic test, and they asked me to accompany them to the appointment. I won’t go into the details, but it was a serious condition. I clearly recall the doctor saying, with a solemn voice and a furrowed brow,\n\n***“The results are back. You’ve got a 1 in 64 chance”***\n\nThis was followed by a few moments of silence and instant, frantic reflection, before we entered a period of deep gloom that lasted several weeks. Thankfully, a follow-up test with a far higher accuracy was performed, and it came back negative (I think the results claimed odds of something like 1 in 300k). We were all relieved, and over the years this negative test result has shown itself to be correct.\n\nI later became increasingly interested in the theory behind diagnostic tests, and I now realise that our response to that initial test result could have been better. Instead of being frozen with fear, we should have questioned the details of the result and the test, and appreciated that such tests are far from complete, particularly when taken in isolation.\n","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"e87df9d1-1def-402c-81bd-d962057c66ea","_uuid":"3196aa33a7061ea854d4fc67edb4765173a92f75"},"cell_type":"markdown","source":"<a id='MedicalTesting'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"34d2e660-3394-4b2e-afd4-d827900075bf","_uuid":"0d9aa6806e0e45919aa10edaa495c6faa9ec74e3"},"cell_type":"markdown","source":"### Medical Testing","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"0495638a-58f9-4b1b-98ca-eb44ad2d8c66","_uuid":"861dec5d82bc17f2d5b13e1fb5eaae6684467f78"},"cell_type":"markdown","source":"***\"Whenever a doctor cannot do good, he must be kept from doing harm\"*** - Hippocrates","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"314fed90-d259-4bc5-8e10-9e6594379b74","_uuid":"7c1c3b107e44f7630a9341465a5f7f94e3e8c088"},"cell_type":"markdown","source":"The act of diagnosing a medical condition is extremely involved$^{[1]}$. When done right, the process is a complex blend of clinical evidence, data, probabilistic rationale and pattern matching, with the consequences of different courses of action kept in mind from a cost and patient care perspective. When done poorly, a range of tests will be performed (often without justification), and conclusions drawn on scant evidence. \n\nMedical tests are designed to detect, diagnose or monitor disease in a patient, and take on many different formats, including clinical examinations, imaging, biopsies, genetic analysis, and blood tests. Beyond their cost and usability, the most important question for any test is its effectiveness. In other words, how good is a particular test at detecting, diagnosing or monitoring the condition in question?\nDiagnostic tests are often sold, marketed, cited and used with **sensitivity** and **specificity** as the headline metrics. Sensitivity and specificity are defined as,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"5bdacae4-74e0-4bb9-9427-c9d6744d1721","_uuid":"4fc927fc55f1904c5cd51718979958b872dca4dc"},"cell_type":"markdown","source":"\\begin{align}\nSensitivity = \\frac{True\\:Positives}{True\\:Positives + False\\:Negatives}\n\\end{align}","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"a2ee2478-a859-4edc-92b2-8d32aebdd6fd","_uuid":"bb8ea4dec224c4648bf6a23ea48faf47542b94e4"},"cell_type":"markdown","source":"\\begin{align}\nSpecificity = \\frac{True\\:Negatives}{True\\:Negatives + False\\:Positives}\n\\end{align}","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"6e7ad1da-48ed-45a2-82b1-23ee33878845","_uuid":"edb59d627974bb72090a764c763f2742b99f282c"},"cell_type":"markdown","source":"Notice the denominators. For sensitivity, we have 'true positives', which are of course positives, and 'false negatives', *which are also positives*. So, sensitivity only deals with positive cases, and the logic is the same with specificity for negative cases. The result is that sensitivity is a measure of the probability of getting a positive result out of all the positive cases, and that specificity is a measure of the probability of getting a negative result out of all the negative cases.\n\nAnother way of phrasing this is that sensitivity is the probability of getting a positive result, given that you have the disease. Note that in practice, we're interested in the opposite of this, namely the probability of having the disease, given a positive test result (and similarly for not having the disease). For these measures, we use the **positive predictive value (PPV)** and **negative predictive value (NPV)**, respectively,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"67046a64-221c-411f-87ac-f3692d307096","_uuid":"f917b05102687eef5bf687712f7f0b51f2accfd9"},"cell_type":"markdown","source":"\\begin{align}\nPPV = \\frac{True\\:Positives}{True\\:Positives + False\\:Positives}\n\\end{align}","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"edd967a6-9bef-42e2-bffb-c89d87a19173","_uuid":"f791f6ce2c00c0eee6fb9ff11e4432b09d5d7482"},"cell_type":"markdown","source":"\\begin{align}\nNPV = \\frac{True\\:Negatives}{True\\:Negatives + False\\:Negatives}\n\\end{align}","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"16b4680c-7c63-4c9e-9199-35f531525996","_uuid":"687a96bd0980df92a1c78f325bbf26f64b20d3ac"},"cell_type":"markdown","source":"Now we have a mix of positives and negatives in the denominators. Despite being arguably more useful, sensitivity and specificity still tend to be the measures of primary focus.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"dda4cf7b-6802-4ed9-9ca0-cdd787566f3a","_uuid":"989970b215fe877b4e8b5d4b26900af0c55cf538"},"cell_type":"markdown","source":"So, let's take a look at some data. Looking at the various Kaggle datasets, the **Pima Indians dataset** looks useful for exploring these ideas,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"61fb871e-96cc-4021-a04a-49bd83970a2f","_uuid":"02967f53b66e9f2c0f8b1c07a12c305652508f8e"},"cell_type":"markdown","source":"#### Pima Indians Diabetes Dataset","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"40305991-d4d2-47bc-954c-cfb1462f78b5","_uuid":"7068cc7db34cbfbbec0bb1b475463965da46b700"},"cell_type":"markdown","source":"This dataset relates to the Pima Indian Population, near Phoenix, Arizona. The study is fairly old, starting in 1965, with a range of variables being chosen based upon their significance in other studies, including the number of times the individual had been pregnant, body mass index, and age.\n\nFirst, let's load the data,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"2e1373ee-e8e1-4b7f-b154-4cc0cf3cde2c","_uuid":"fddaa7f159a3582c71daa8a4d41591cc2039aed3","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\ndiabetes = pd.read_csv('../input/pima-indians-diabetes-database//diabetes.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"31d11033-1af2-4cc4-9cda-f50ff740b598","_uuid":"4725552be2fa2a32c664012649e4aa32e5a16b2c"},"cell_type":"markdown","source":"Then have a quick look at the details,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"9fdc1bfc-f0ea-4b53-9eba-d74fee6c42f4","_uuid":"4e1aae909fe68d3ae34dd02bfe0eab1de122097a","trusted":true},"cell_type":"code","source":"diabetes.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f27df8e6-9587-4a59-bee7-f44b7f0f56d5","_uuid":"bd3018ee114053b875904ab6bd4654358a21bdc3"},"cell_type":"markdown","source":"Looking at some of the actual data always helps,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"a2f3e3b9-72a5-44ba-ba8e-de55df96821c","_uuid":"147066f616457e0bdd2161c8d888858bde391fd5","trusted":true},"cell_type":"code","source":"diabetes.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b2a11a97-e5f7-43d2-a014-770b7a5b107a","_uuid":"3fce2d43a2c7064a726b7a7fdd8286fbe28d2403"},"cell_type":"markdown","source":"As you can see, there are a number of 'medical' related pieces of information. Using the lexicon of machine learning, we can frame this data as having one **target variable** ('Outcome'), with the rest being **predictor variables**. The outcome field is a Boolean telling us whether or not the person in question had diabetes or not.\n\nLet's put together a very simple model to predict this outcome based upon some of the predictor variables. Note that I'm not going into the statistics of machine learning here (Kaggle has plenty of examples!). What I'm concerned about is the *interpretation* of the results, rather than optimising the underlying model.\n\nBefore diving into creating the model, let's briefly explore the data. First, what is the balance of outcomes?","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"4775e2fc-818e-40d2-8a50-5e70a57f615f","_uuid":"d1c48fec0a3c7e4fde466dc27ac51b8c1009f7bc","trusted":true},"cell_type":"code","source":"import seaborn as sns\n%matplotlib inline\n\nsns.countplot(x='Outcome', data=diabetes, palette='hls')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13f0e7a6-67a6-421f-92da-d1d297a2cc3e","_uuid":"0a38d205e4dda717df624dd8c247a14e988902d3"},"cell_type":"markdown","source":"What about looking at some mean numbers, according to outcome?","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"01732855-352a-4551-82a6-0c498d7ad1f7","_uuid":"a6cd75c43d0ac3c922b7e93778fc937101e24354","trusted":true},"cell_type":"code","source":"diabetes.groupby('Outcome').mean()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9d5e45ca-a302-4822-8a25-ec3ba8754741","_uuid":"ff67a4ff3da99eafbcd4fdd40e83ae4042d60d46"},"cell_type":"markdown","source":"It looks like if you have 4.86 children, you might be in trouble.\n\nNext, I'll load a few bits and pieces, and then check for any missing values,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ac89b150-751e-4cd3-b0ef-bb8c40ff36eb","_uuid":"b08092619c10f101817f1bc5d4031dcc133f2050","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn import linear_model, datasets, metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, auc\nimport math\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1c6ef958-8020-4bfc-b420-1d3f509d74df","_uuid":"2c3f9410663f9e85995eee93753a25575f24c4a0","trusted":true},"cell_type":"code","source":"diabetes.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"40491628-76f7-4302-aa79-b01b50d5bcf0","_uuid":"a07af87c9c9d295e8cfa70480e4787be3e8ce4b1"},"cell_type":"markdown","source":"I don't know a lot about diabetes, but I'm pretty sure glucose is important! Let's use a box-plot to see the difference in terms of outcome,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"77492a81-2e22-45d4-9fa1-7f02bd3f196e","_uuid":"fecbba6bad0d820f1ed397f6ec6719a776005242","trusted":true},"cell_type":"code","source":"sns.boxplot(x='Outcome', y='Glucose', data=diabetes, palette='hls')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b13524d8-9e91-41ec-aa1d-1c64a8313abd","_uuid":"96e6239021bd93c2d9ae42db4165049f9216688c"},"cell_type":"markdown","source":"So, glucose is raised, on average, in cases with diabetes. And of course, if we wanted to get into feature selection, the classic **correlation plot** would be useful,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"bd81dd86-ac36-44e4-b6f7-359718eb2ec8","_uuid":"c293d373c4e35b3ebc0409a4a92afd772b02cfbf","trusted":true},"cell_type":"code","source":"sns.heatmap(diabetes.corr())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d864e7f2-9c85-44a9-bebf-ebe561ae60fb","_uuid":"25911f9e1ad3aaeb3c093e5384fa7a7f90ba8ad3"},"cell_type":"markdown","source":"OK, let's create a quick, crude model using logistic regression (including splitting into training and test sets, and making predictions),","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"9ff7e909-cfa9-4f8d-ab00-51c97c966172","_uuid":"a484d05e4029715a3fbb6e43bbffca53c2ed6042","collapsed":true,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(diabetes.drop('Outcome', 1), diabetes['Outcome'], test_size = .3, random_state=25)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7acbd687-b429-4d28-9ca0-571e4f9f3d47","_uuid":"d32bb24aca9f7ea9c865b360ffb3d67fadca01b2","trusted":true},"cell_type":"code","source":"LogReg = LogisticRegression()\nLogReg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"499615af-ee62-4e3d-b182-c08249ef0abf","_uuid":"987a8ad25a8e4856b0f604cd787c37f15fadc34c","collapsed":true,"trusted":true},"cell_type":"code","source":"y_pred_quant = LogReg.predict_proba(X_test)[:, 1] #Only keep the first column, which is the 'pos' values\ny_pred_bin = LogReg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e4ddd99f-c077-4119-b16e-cbd78c760905","_uuid":"66e5aae79b2c61d8865e21cfe83322d67c2b8e28"},"cell_type":"markdown","source":"[](http://)Now let's create a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix), and work out the sensitivity and specificity,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"991360a6-95c1-44a3-a98d-0777540ec95d","_uuid":"75395b3ea364365943d503bf3d2fd771feb654e9","trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = metrics.confusion_matrix(y_test, y_pred_bin)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"918e4975-c15d-4c42-b5c3-6410a03d78cf","_uuid":"68984adbd4ca8e08ccbbc41d51717a8345f759b5","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ntotal=sum(sum(confusion_matrix))\n\nsensitivity = confusion_matrix[0,0]/(confusion_matrix[0,0]+confusion_matrix[0,1])\nprint('Sensitivity : ', sensitivity )\n\nspecificity = confusion_matrix[1,1]/(confusion_matrix[1,0]+confusion_matrix[1,1])\nprint('Specificity : ', specificity)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3e68f3f2-003b-49b1-b8da-4dc5c18b21f2","_uuid":"c9dac856d270812bf09f2cbd729593f0f7868953"},"cell_type":"markdown","source":"Now we encounter the first issue in the world of diagnostic testing, which is that sensitivity and specificity are often treated as static, where-as it of course depends upon the threshold you choose for determining what classes as a positive and what classes as a negative. To check the full range, we use a **[Receiver Operator Curve (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)**,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"7dd58788-cab9-4b1d-be81-aaddb02a8bb6","_uuid":"e0b4ce75c285c1b5ead674d99b26aec540a40810","collapsed":true,"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_quant)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e998a21e-d209-4466-9c2f-6b850a4afac9","_uuid":"c44d6b535ff4d057c6de06f1d7ff02b8b4154a77","trusted":true},"cell_type":"code","source":"plt.plot(fpr, tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for diabetes classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4991ab9d-ca0b-4b78-a3b4-b8ae26554eb4","_uuid":"daa97c98d3fb5eb34e069e0ea9072bf76613b4fb"},"cell_type":"markdown","source":"Another common metric is the **Area Under the Curve**, or **AUC**. This is a convenient way to capture the performance of a model in a single number, although it's not without certain issues$^{[2]}$. As a rule of thumb, an AUC can be classed as follows$^{[3]}$,\n\n- 0.90 - 1.00 = excellent\n- 0.80 - 0.90 = good\n- 0.70 - 0.80 = fair\n- 0.60 - 0.70 = poor\n- 0.50 - 0.60 = fail\n\nLet's see what the above ROC gives us,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ddf966a7-4ec0-48c4-994b-c561366a53c7","_uuid":"f249bac20568c9e8997be40300aa01dfad3225b9","trusted":true},"cell_type":"code","source":"metrics.auc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6f20e140-34e2-4195-9a73-7f3e2085d76e","_uuid":"15f9df56c06b7776169914c3575a78ae455631bb"},"cell_type":"markdown","source":"Borderline good!","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"151f7817-bbe3-4861-83eb-4fe39508e8b4","_uuid":"06948f58b4472f45a52c324d8875057397b25e84"},"cell_type":"markdown","source":"<a id='DevelopingaDiagnosticTest'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"2b9e01a5-99ec-4c42-9b4c-9a29492a7da8","_uuid":"2fd1eea72b4d80a0de5ae6be796d62f861129255"},"cell_type":"markdown","source":"### Developing a Diagnostic Test","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"409a60fe-ce14-46da-80d6-96246b6be0c1","_uuid":"04684fa18a11595ff6ea22d11fc5cbef1bb29f32"},"cell_type":"markdown","source":"***\"I am dying from the treatment of too many physicians\"*** - Alexander the Great","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"a6bd8dac-6c09-4955-b56c-68001f82582c","_uuid":"ba2e55db878cc5f640e591756bb13ce283d61cdc"},"cell_type":"markdown","source":"So far, so good. You have a dataset with dozens of predictor variables, you throw them at an algorithm, and you end up with a model to predict new cases. In the medical diagnostic world, however, this isn't how it usually works. The first reason for this is that gathering well characterised cases is hard, because to be able to call one sample 'disease A' and another 'disease B', you have to follow these cases up, perhaps with expensive '[**gold-standard tests**](https://en.wikipedia.org/wiki/Gold_standard_(test)', and/or follow them for many months to see how their condition evolves. Another complication is that people often have more than one thing wrong with them, so seeing that a certain blood-marker is raised in a person with diabetes *might* be due to the diabetes, but it may also be due to some other underlying condition.\n\nWhat you're typically left with in the case of tests using blood markers, is a relatively low number of cases (a few hundred if you're lucky) with one or more markers measured. These cases may also have some clinical information. Often, a test is based upon just a single marker (take a look at [**acute phase proteins**](https://en.wikipedia.org/wiki/Acute-phase_protein) for instance), with no additional information. No fancy machine learning is employed, it is simply a case of measuring the marker of interest in two cohorts of patients, picking an appropriate cut-off (usually via ROC analysis), and then commercially launching the test. Let's see what this looks like with the **Indian liver patients dataset**,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"987ad0d8-4bfd-4adf-adcc-704cd743fec5","_uuid":"6e7df63cbb05500870f2b32fc3df68cfb6a760c3"},"cell_type":"markdown","source":"#### Indian Liver Patients Dataset","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"e508cffb-e206-4479-b045-8acca8af3060","_uuid":"cd3aeba2ed989c0982c4900cb769a4db1b8d81be"},"cell_type":"markdown","source":"To quote verbatim from the [UCI Machine Learning Repository website](https://archive.ics.uci.edu/ml/datasets/ILPD+(Indian+Liver+Patient+Dataset), *\"This data set contains 416 liver patient records and 167 non liver patient records.The data set was collected from north east of Andhra Pradesh, India. Selector is a class label used to divide into groups(liver patient or not). This data set contains 441 male patient records and 142 female patient records. Any patient whose age exceeded 89 is listed as being of age \"90\"*.\n\nLet's take a look,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"39835af9-4310-4161-9f42-6c4c00158b52","_uuid":"e34d3792fafb3268ee953391c116c4c6c6f1f8b2","collapsed":true,"trusted":true},"cell_type":"code","source":"liver = pd.read_csv('../input/indian-liver-patient-records/indian_liver_patient.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"590391a0-ebf3-4cb4-9633-f159d1405fc8","_uuid":"0a587b860a3e9aaf84b9ab85a3f0ed488fa71a1d","trusted":true},"cell_type":"code","source":"liver.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3e7f3010-c8ba-4aaf-8b3b-2726af965efd","_uuid":"005bb0e5605714b92add6f14fb61520ac963c231","trusted":true},"cell_type":"code","source":"liver.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e3c1b0b7-41bb-4b87-9428-ddd9c6976a9f","_uuid":"3703e51451fbca46abc5d0c72393930b333d5719"},"cell_type":"markdown","source":"We have all sorts measured here. However, for the benefit of this example, imagine if the only thing we had was 'Total_Bilirubin' and the outcome.\n\nNote that I'm going to change the 'Dataset' column name to 'Outcome', in order to be consistent with the analysis above. I'm also going to change the 1s and 2s in this column to 1s and 0s (initial state is that 1 = liver disease, 2 = no liver disease),","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"2c03bc37-894c-4157-ad2a-1dc168641a11","_uuid":"32755524a9fd3e315d586f8858480173e8de6f9f","collapsed":true,"trusted":true},"cell_type":"code","source":"liver.rename(columns = {'Dataset':'Outcome'}, inplace = True)\nliver['Outcome'].replace(to_replace=2, value=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3adf62d5-a58c-42df-8b5b-6e4cca3a93c6","_uuid":"03f8a32d182df6ad5ab650e0ad4468315a1a924a"},"cell_type":"markdown","source":"Check the summary by outcome,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"bf5e34bf-3f8f-4e62-ba06-18120c139206","_uuid":"ac89b0688c2fd2f6f2f01790ee86bc439c8650e0","trusted":true},"cell_type":"code","source":"liver.groupby('Outcome').mean()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56c34651-314d-4007-b9df-04d79f6790f5","_uuid":"548e57b45025312bdf319a0e2d6149459981cbcf"},"cell_type":"markdown","source":"Let's just grab the two columns we're interested in,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"b2639062-e678-4a9b-9269-d325bb0693cd","_uuid":"bee1689f483f1f67ebd731aa0e29b351e5add959","collapsed":true,"trusted":true},"cell_type":"code","source":"liver_sub = liver.iloc[:,[2,10]]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eb8c1ee2-bf18-4ccc-8940-054d3fb439f6","_uuid":"4bf4f5a7bf40a24a73cffbf484493e083744e7a1","trusted":true},"cell_type":"code","source":"liver_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0f1faac2-3e5d-442d-8c75-7f1f22c0c4ca","_uuid":"ea33d69a6abaf3b231a8ca5257b9bbd6d3295844"},"cell_type":"markdown","source":"Let's sanity-check whether or not we think there is any discriminatory power in this marker with a box-plot,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"7bfb74a7-1309-4c1c-9a70-9e3a474cd0c9","_uuid":"ce88a3c03839d65fa1d452d8d1937c9182391990","trusted":true},"cell_type":"code","source":"sns.boxplot(x='Outcome', y='Total_Bilirubin', data=liver_sub, palette='hls')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"78292044-07af-4f03-8c09-8d486eca08cb","_uuid":"3bdbbcc67b92c3ccbc392b0aa26f4958947ae548"},"cell_type":"markdown","source":"It looks like Total Bilirubin is raised in liver condition cases, especially in the case of the outliers. Let's also check without the outliers,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"37921187-16a1-4253-ab05-320a53e30a0e","_uuid":"9fb78959847395b6df07241725ff704e504f23a7","trusted":true},"cell_type":"code","source":"sns.boxplot(x='Outcome', y='Total_Bilirubin', data=liver_sub, palette='hls', showfliers=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aa968055-e22c-4e89-8efe-cae2b18ab32e","_uuid":"f33cf5a2a155530bcfef92014a7a47d08b0f85d4"},"cell_type":"markdown","source":"We could also check things with a histogram,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"999a96a8-442a-4b4d-b2d3-8d52a46e19fd","_uuid":"4d711f6652208dce9fc70e32350f3c6d08d943de","trusted":true},"cell_type":"code","source":"bins = np.linspace(0, 80, 100)\n\nplt.hist(liver_sub['Total_Bilirubin'][liver_sub['Outcome'] == 0], bins, label='No disease',fc=(0, 0, 1, 1))\nplt.hist(liver_sub['Total_Bilirubin'][liver_sub['Outcome'] == 1], bins, label='Disease',fc=(1, 0, 0, 0.4))\nplt.legend(loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3f04d211-82d3-4958-ae95-0fa9dd96e2fc","_uuid":"5469299d231462d35f287298166f853bca470110"},"cell_type":"markdown","source":"OK, there is definitely some difference here. This makes physiological sense, as bilirubin is known to be a by-product of the breakdown of red blood cells, which should be efficiently dealt with by the liver. So raised levels can indicate that the liver is not functioning correctly$^{[4]}$. That said, there is overlap, so we shouldn't be surprised if the separation of the two groups with some cut-off value and the consequent sensitivity and specificity are fairly poor.\n\nLet's keep going with this marker and create a ROC plot from scratch. The following code evaluates the sensitivity and specificity at 100 different thresholds across the range of the Total_Bilirubin, then plots the results,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"2faba29d-057d-4ef8-aced-c0d46b0be4a1","_uuid":"337da7bcbd6bd66fd9b64e8398749dd3b0b06d0a","collapsed":true,"trusted":true},"cell_type":"code","source":"tb = liver_sub['Total_Bilirubin']\npred = np.zeros(tb.size)\ntb_min = np.min(tb)\ntb_max = np.max(tb)\ntb_range = tb_max - tb_min\nthresh_inc_size = 100\ntb_inc = tb_range / thresh_inc_size\nno_thresholds = tb_range / tb_inc.size\nno_thresholds = np.ceil(no_thresholds)\nno_thresholds = no_thresholds.astype(int)\nsens = pd.Series(np.zeros(no_thresholds))\nspec = pd.Series(np.zeros(no_thresholds))\n\ntb_cutoff = tb_min\ni=0\ny=0","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f88e29f1-3d87-45a4-beda-cf27f4208a24","_uuid":"03caaf2909ff01c4ee66954f856509b588ef2940","collapsed":true,"trusted":true},"cell_type":"code","source":"while (y <= thresh_inc_size):\n    while (i<tb.size):\n        if (tb[i] >= tb_cutoff):\n            pred[i] = 1\n        else:\n            pred[i] = 0\n        i=i+1\n    confusion_matrix = metrics.confusion_matrix(liver_sub['Outcome'], pred)\n    sens[y] = confusion_matrix[0,0]/(confusion_matrix[0,0]+confusion_matrix[0,1])\n    spec[y] = confusion_matrix[1,1]/(confusion_matrix[1,0]+confusion_matrix[1,1])\n    i=0    \n    y=y+1\n    tb_cutoff = tb_cutoff + tb_inc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5dfc2b14-ba25-48f4-9362-d9294eef530c","_uuid":"db0f52a55c123148d60e58185f41f881043c76b4","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(1-spec, sens)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for liver disease classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e1e234f6-c65b-4895-a553-0f3168e6e36d","_uuid":"e91a1689a65baee861e92c7caee85a1414bacc17"},"cell_type":"markdown","source":"To reiterate, this ROC plot has *not* been generated by varying the probability between 0 and 1 like machine-learning applications. Now, the threshold that is being varied is the blood marker value, between the minimum and maximum values.\n\nThere are various ways to pick the most suitable cut-off point. Some use the **Youden index**$^{[5]}$\n, which is a way to balance sensitivity and specificity by selecting the point on the ROC plot that maximizes the difference between sensitivity and 1-specificity. However, one thing to keep in mind here is that a false positive may not perfectly equal a false negative in terms of cost. For example, in medical testing, a false positive may lead to the administration of drugs that aren't needed, resulting in side-effects and financial costs, but a false negative could lead to death. Arguably not the same!\n\nAlternatively, a high sensitivity may be selected (at the expense of specificity) for a **rule-out** test, or a high specificity may be selected (at the expense of sensitivity) for a **rule-in** test.\n\nFrom the plot above, you can see that at a moderate sensitivity of 0.8, you're getting a poor specificity of ~0.5. Better than a coin-toss (the dotted line), but not amazing.\n\nThere are a number of good papers on using ROC plots with diagnostic tests$^{[6-8]}$\n\nNext, let's take a look at a different Kaggle dataset,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"844e56b7-6d70-4684-b831-cb08e0086343","_uuid":"f07b30f5bc428ad7026102da96d1fcfd6aebf5cf"},"cell_type":"markdown","source":"#### Breast Cancer Wisconsin (Diagnostic) Data Set","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f62304ef-e451-40c3-b36c-823360f8d921","_uuid":"5ad858a0cdac22fe5c8bfe866dfacc857e22adb9"},"cell_type":"markdown","source":"This dataset contains information on cell shape for individuals with benign or malignant tumours. According to the UCI website, *\"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image\"*\n\nLet's load the data and have a look,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"d928c2b3-2a8f-427b-afa9-c07d9366be94","_uuid":"e2398adfa877be0fc927f966a1e08eccf5175e02","collapsed":true,"trusted":true},"cell_type":"code","source":"bcancer = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a88c3c9f-15e2-4f81-a2f1-10430d780fcb","_uuid":"08da5b4274dc4444b3ef8dbb6f73c7d0dc432949","trusted":true},"cell_type":"code","source":"bcancer.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7b6abd7c-d8fc-4fde-819c-605e11ef85fe","_uuid":"741966e9a905c47e5b6d699996e562b504fe6e98"},"cell_type":"markdown","source":"Lots of variables here. Let's see some data,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"998f0f9c-2686-4625-8087-2bc81a6e34f3","_uuid":"12338c726febefc3170bc37963be2b37313c1566","trusted":true},"cell_type":"code","source":"bcancer.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ee300d18-d803-4f98-b02a-d180111cc538","_uuid":"9d4c35a4d2b440938fe8f2e5ccb7f6906f82a45d"},"cell_type":"markdown","source":"And a look at the different features by the two classes (benign and malignant),","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"49ba64e9-775b-4860-a321-868ce0f9b554","_uuid":"65042ef3bc41fa3b95f237dc297a1d2b28b5efc2","trusted":true},"cell_type":"code","source":"bcancer.groupby('diagnosis').mean()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"36e3c1a4-88a2-44a8-a287-43239e91a21d","_uuid":"bedfa8aeec3d9103d85963e544c5251488e94a63"},"cell_type":"markdown","source":"It looks like there are some differences here. Let's grab a few and create a model and a ROC plot. Again, I'm not trying to revolutionise cancer diagnostics, but it would be good to get a new example for some of the bits that follow,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"28a7877e-0242-4558-bf2c-16cc6bcc1528","_uuid":"e6eba09a7899b4070adec6b9082d045211b14e24","collapsed":true,"trusted":true},"cell_type":"code","source":"bcancer_sub = bcancer.iloc[:,[1,5,8]] #These features were found to be useful in other Kaggle kernels","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c9ab6923-e71b-421f-a43f-4ffbaad494cf","_uuid":"efe9756c91ba19aa90b435c9d311fadb1cb8234e","trusted":true},"cell_type":"code","source":"bcancer_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b2c9612c-eba8-44b1-b961-a14f7abfe9b4","_uuid":"ab39325a5809a821efb88580329188cc0de8442a","collapsed":true,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(bcancer_sub.drop('diagnosis', 1), bcancer_sub['diagnosis'], test_size = .3, random_state=25)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cbf85d20-f09b-4422-94e5-35f28ccb25f4","_uuid":"2205b87b5bc712161aa9620c6fc932f75a75fda9","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ed67aa0c-fa36-49db-a071-089730137aaf","_uuid":"3d5fa663f92b9c14bfc8650440fff7c278ead6ac","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\nnp.random.seed(seed=100)\ndtree = DecisionTreeClassifier(criterion = \"gini\", random_state = 10, max_depth=3, min_samples_leaf=3)\ndtree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1ee58522-11fb-4fcc-a912-289f43a3b745","_uuid":"6d860caae9305bf546981c8593937f345a98d714","trusted":true},"cell_type":"code","source":"y_pred_quant = dtree.predict_proba(X_test)[:, 1] #Only keep the first column, which is the 'pos' values\ny_pred_bin = dtree.predict(X_test)\n\nconfusion_matrix = metrics.confusion_matrix(y_test, y_pred_bin)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1f0b3b3e-3646-42ac-9667-aa15a212c4ca","_uuid":"7481c723301e4f94c9245e5b91c4def1c4e2c37e","trusted":true},"cell_type":"code","source":"total=sum(sum(confusion_matrix))\n\nsensitivity = confusion_matrix[0,0]/(confusion_matrix[0,0]+confusion_matrix[0,1])\nprint('Sensitivity : ', sensitivity )\n\nspecificity = confusion_matrix[1,1]/(confusion_matrix[1,0]+confusion_matrix[1,1])\nprint('Specificity : ', specificity)\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_quant, pos_label='M')\n\nplt.plot(fpr, tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Breast Cancer classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)\n#plt.axhline(y=sensitivity, color='r')\n#plt.axvline(x=1-specificity, color='r')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"797b54a7-c64b-4041-ae80-4cbf9664b963","_uuid":"d872a6ae3b3b0b153dec2aa5a6be3dfe7325bfa9"},"cell_type":"markdown","source":"Let's check the AUC,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"7d85140a-4ce8-4789-bd4f-15620bb1509e","_uuid":"7bab5949dbc7e67670295359c7370ef5f4336960","trusted":true},"cell_type":"code","source":"metrics.auc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"867d4787-88c7-431a-a71e-eabdaa13a13f","_uuid":"acafa8ef0e7173c629391d68bd200093b6c9a913"},"cell_type":"markdown","source":"Not bad.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"d82b75a2-0e22-465d-8579-cf1b549ef24d","_uuid":"54c0381de178113dc762ec4f7c9d5559ae5a6707"},"cell_type":"markdown","source":"<a id='Testdevelopmentisdone?'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"7c95cc8c-ae75-43e8-abb3-b74805e51ec9","_uuid":"ef14c2b45c2cbd598be81864a0e7f0261f856445"},"cell_type":"markdown","source":"### Test development is done?","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"b8dcea4d-eabd-45e9-b25d-4091cfdf4a58","_uuid":"cbdff536e047146ef8d858e59b7e7bde06dddbc2"},"cell_type":"markdown","source":"***\"Either do not attempt at all, or go through with it\"*** - Ovid","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"aafb4f3f-911e-48bf-b2e1-25af7a779ae2","_uuid":"78cabd1b1a0c22c2c836ef10b92e4444f44f9607"},"cell_type":"markdown","source":"In my experience, this is about as far as many diagnostic tests get. Some don't even go as far as creating a ROC plot, some are only based on a single predictor variable, and some only quote sensitivity *or* specificity. Leaving those concerns aside, the situation that this leaves is that often there is a fixation on these two numbers, and it has effectively led to a battle within the literature of *\"my sens and spec are better than your sens and spec\"*. \n\nIn reality, a number of fundamental problems exist with this approach. These include,\n\n1. Sensitivity and specificity are measurements of how the test performed on a past cohort. They are, therefore, general measurements of the test performance against a sample, and not specific for the individual patient in question\n2. These metrics are only useful if the chosen test patients are relevant to the test. A common failing here is to include healthy patients when the test is only ever to be used on diseased individuals$^{[9, 10]}$. In other words, these metrics are only useful if the patient in question is from a population that matches that that the test was developed upon (in terms of both disease type and disease prevalence)$^{[9, 10]}$\n3. Sensitivity and specificity can be altered based upon the threshold used. The full range of possible options should be given in the form of a Receiver operating characteristic (ROC) curve, but often it is not, focussing instead on a single, often arbitrary point$^{[11]}$\n4. Confidence intervals are rarely focussed upon\n5. Ruling out or ruling in, with a focus only on sensitivity or specificity fails to take into account a test’s true predictive ability. This may mean that the results of the test are not ruling out or ruling in to the degree expected$^{[12,13]}$\n\nThe solution to items 2 – 5 on this list is simply to do better science. Indeed, papers have been published with the sole aim to improve the design and consequent reporting of diagnostic tests, including **'Standards for\nReporting Diagnostic accuracy studies' (STARD)** $^{[9, 10]}$.\n\nAnother factors are **cost**, **risk** and **urgency**. What if you have two tests with comparable sensitivity and specificity, but the one that is slightly higher costs twice as much as the other, takes twice as long and comes with potential side-effects? Now the improved performance may be deemed insignificant.\n\nThis list also alludes to an elephant-sized issue with diagnostic test development, that of **bias**[14]. To elaborate, sources of bias include the following,\n\n- **Selection bias** - Eligible cases aren't selected randomly\n- **Spectrum bias** - Cases don't correctly represent the target condition or severity of condition\n- **Misclassification bias** - When the cases aren't classed correctly (i.e. 'with disease' and 'without disease')\n\nEtc.\n\nBefore moving on, I want to highlight item 4 in the above list (confidence intervals), as this is one that we can demonstrate with data.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"8f5f0692-1d02-4150-bec0-e17f54113795","_uuid":"8367e88401435f3319210d92e6c0940b9990a494"},"cell_type":"markdown","source":"<a id='ConfidenceIntervals'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"cf995b60-7c8f-4aa6-99a7-c4dc28350f98","_uuid":"014a59039318848a92c2e9d3e3c0537912901bc6"},"cell_type":"markdown","source":"### Confidence Intervals","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ff78827e-4e8d-4504-aa16-f192d843b0a5","_uuid":"5c9a2720440f3901d65f7ccf2b3a845dd69d8bbd"},"cell_type":"markdown","source":"***“I couldn't claim that I was smarter than sixty-five other guys--but the average of sixty-five other guys, certainly!”*** - Richard Feynman","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"77062da6-b86d-4563-a06e-5abf65c37d30","_uuid":"3704ee1dd1baea941b4a77975b1ef263ef6af056"},"cell_type":"markdown","source":"Flicking through any statistics book will reveal a seemingly limitless array of theorems, equations, models, tools and techniques. Understanding the details of them all is extremely difficult, not-to-mention arguabley inefficient given the number of guides available that point you in the direction of which bits of stats you need for a given problem or data type. \nThat said, having a good understanding of some core principles can help enormously, both in the understanding of your own results, and in order to critique the findings of others. One of these, I would argue, is the [**central limit theorem**](https://en.wikipedia.org/wiki/Central_limit_theorem). The consequences of this theorem are wide-ranging, but the one of interest here is that of [**confidence intervals**](https://en.wikipedia.org/wiki/Confidence_interval). If you're not sure what they are, I encourage you to follow the previous links to find out more.\n\nHere, the consequence of confidence intervals are that for metrics such as sensitivity and specificity, what we have in reality are *estimates* of values, due to the fact that we only have a sample of cases from a wider population. The consequence of this is that if people are promoting a test with high sensitivity as a rule-out test (or high specificity for rule-in), if the lower value from the confidence limits is significantly lower, then your test may be no-where near good enough for this purpose. \n\nLet's see an example. From the quick model above, we have a specificity of ~0.93. Some may claim that that's sufficient to rule-in a disease (typically you'd want it higher than that, but let's assume 0.93 is okay for our purposes). Now let's look at the confidence interval for the sensitivity and specificity. To do this, we'll use a technique called [**bootstrapping**](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)), which samples many times from the training data, creates a new model for each one, and generates a sensitivity and specificity for each model,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"13560907-5987-4873-b72d-f82bde05b0fc","_uuid":"1c726e95b41d01d2dbffe94ae1e470e0a0bf0452","trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\n\nspecificity_orig = specificity\n\n# configure bootstrap\nn_iterations = 1000\nn_size = int(len(bcancer_sub) * 0.25)\n\n# run bootstrap\nsens = list()\nspec = list()\n\nfor i in range(n_iterations):\n    # prepare train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(bcancer_sub.drop('diagnosis', 1), bcancer_sub['diagnosis'], test_size = .3)\n    # fit model\n    dtree = DecisionTreeClassifier(criterion = \"gini\", random_state = 10, max_depth=3, min_samples_leaf=3)\n    dtree.fit(X_train, y_train)\n    # evaluate model\n    y_pred_quant = dtree.predict_proba(X_test)[:, 1] #Only keep the first column, which is the 'pos' values\n    y_pred_bin = dtree.predict(X_test)\n    confusion_matrix = metrics.confusion_matrix(y_test, y_pred_bin)\n    sensitivity = confusion_matrix[0,0]/(confusion_matrix[0,0]+confusion_matrix[0,1])\n    specificity = confusion_matrix[1,1]/(confusion_matrix[1,0]+confusion_matrix[1,1])\n    sens.append(sensitivity)\n    spec.append(specificity)\n    \n# plot scores\nplt.hist(spec)\nplt.axvline(x=specificity_orig, color='r')\nplt.show()\n\n# confidence intervals\nalpha = 0.95\np = ((1.0-alpha)/2.0) * 100\nlower = max(0.0, np.percentile(spec, p))\np = (alpha+((1.0-alpha)/2.0)) * 100\nupper = min(1.0, np.percentile(spec, p))\nprint('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"29adcf71-698d-4c2c-a296-0f4bfcd99ee1","_uuid":"0d51651094736fcd9b6dea6f9de48a9eaacdaa87"},"cell_type":"markdown","source":"*Thanks to [Machine Learning Mastery](https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/) for help with the bootstrapping*","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"0b56b096-3ea4-4e75-93ff-0e07b578d608","_uuid":"23e73c524567bf2f0d1e21278783cf829c7725e8"},"cell_type":"markdown","source":"So, we have a significantly lower specificity at a 95% confidence level. No-where near good enough to rule-in. This is another aspect of diagnostic testing that is often overlooked.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"3eb45831-da93-4792-8003-b34d535b39a9","_uuid":"5bb1c25b60b1cfce75f3fa17cb29f7c08a7683ee"},"cell_type":"markdown","source":"Returning to the list of diagnostic test problems, item 1 on the list is particularly fundamental, and requires a different approach to diagnostic testing in general. The way to do this is not novel, and has been in the literature for a number of decades. However, its understanding and application are not straightforward and these facts have hindered widespread use. Let's take a look...","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"2d5094b1-dd75-4407-aa68-7df81c65c5a9","_uuid":"77aa24ab0868652b3251198244c2af1ffb9da113"},"cell_type":"markdown","source":"<a id='EnterRevBayes'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"e94a3b7d-15ef-4d72-992b-4bad50744696","_uuid":"eda6916133296ffb297c92c191c1752f8cb4d1b8"},"cell_type":"markdown","source":"### Enter Rev. Bayes","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"76ed3bc3-4de2-428e-9567-8d5a77b881b9","_uuid":"70cfe02f841a4ea7d2626bd5319775421548a58d"},"cell_type":"markdown","source":"***\"The world is full of obvious things which nobody by any chance ever observes.\"*** - Sherlock Holmes Quote (The Hound of the Baskervilles)","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"56232722-91f0-457e-adb7-1a34cbe8054b","_uuid":"703dc7f269dd28e921f673c8cb0e85701ef07568"},"cell_type":"markdown","source":"Bayesian statistics is a topic often seen in machine learning circles. However, in my experience, the area often used is that of using [**Markov Chain Monte Carlo (MCMC)**](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo) to ascertain the details of one or more posterior distributions. The fundamental idea of [**Bayes Rule**](https://en.wikipedia.org/wiki/Bayes%27_theorem) is much simpler, and is simply the idea of updating prior beliefs based upon new information. In the diagnostic world, this simple idea can be incredibly powerful$^{[15]}$, but unfortunately, often ignored.\n\nTo show what I mean, in a paper by Reid et al$^{[16]}$, 300 physicians were surveyed regarding their use of test accuracy metrics, and it was found that just 3% used the recommended formal Bayesian calculations (with a large number citing a lack of understanding of sensitivity, specificity, ROC curves and likelihood ratios for their lack of use). Another paper by Whiting et al$^{[17]}$ also concluded that *\"Commonly used measures of test accuracy are poorly understood by health professionals\"*.\n\nThe prevailing type of statistics and that used in all traditional applications is known as [**frequentist**](https://en.wikipedia.org/wiki/Frequentist_inference) statistics. This approach assigns probabilities based upon the frequency of events occurring. In contrast, in the [**Bayesian**](https://en.wikipedia.org/wiki/Bayesian_inference) mindset, probabilities are related to our current level of knowledge about an event. This latter approach allows the introduction of something called a [**prior**](https://en.wikipedia.org/wiki/Prior_probability) (explained in more detail later), which is a probability assigned *before* data is collected on an event. This prior is combined with new evidence to give a **posterior** probability.\n\nIt represents, therefore, (as the name suggested) a prior belief. To the Bayesian, this is Bayesian statistics’ biggest strength, as it allows the full weight of pre-existing evidence and domain knowledge to be brought to bear$^{[18]}$. To the frequentist, this is Bayesian statistics’ biggest weakness, as it introduces a subjective element into what is an objective branch of science. \n\nThis prior can be deduced in many ways. At the most subjective, it is simply a gut-feeling for the probability of something (for example, the probability of disease based upon experience and training). Less subjective is a local **prevalence**, for example, the prevalence of a certain disease in a certain clinic. The most rigorous way of determining a prior is through a process known as **elicitation**. This is where a prior probability is determined from a careful examination of the situation. For example, this may be via a series of well-designed questions regarding the state of an individual patient.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"9b9028d1-613c-4deb-b95f-cfd6235d0ff9","_uuid":"e4b655300e6829dfc4248fdd5d535eb18db83fbc"},"cell_type":"markdown","source":"<a id='TheproblemwithsensitivityandspecificityAnexample'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"2368faa5-d1c9-439e-a1c0-749a3abc7987","_uuid":"e8efd75505584af27bd82ce5f825bb2354087378"},"cell_type":"markdown","source":"### The Problem with Sensitivity and Specificity: An Example\n\nSensitivity is the probability of getting a positive result given the presence of the disease. It is test-specific and says nothing about the individual patient. Instead, what the patient cares about is the inverse; the probability of having the disease given a positive result. This can be computed using [Bayes rule](https://en.wikipedia.org/wiki/Bayes%27_theorem), which is,\n\n\\begin{align}\nP(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n\\end{align}\n\nThis reads as ‘the probability of A given B is equal to the probability of B given A, multiplied by the probability of A, divided by the probability of B’. Notice that it's giving us P(A|B) using P(B|A), which is what the PPV gives us compared to sensitivity, as mentioned previously. PPV can be derived from Bayes rule, but doing it that way *assumes that the patient in question has a prior probability approximately equal to the prevalence in the reference group*. If that's not the case, then you need to use Bayes rule with your alternative prior, as shown below.\n\nIn the equation above, P(A) is the probability of having the disease and P(B) is the probability of getting a positive result. What are these values? P(A) is the prior (mentioned above). Local disease prevalence is often used for P(A) and will be used in the example below. P(B) is the combination of all the ways a positive result could be obtained, i.e. the patient could have the disease and get a positive result or the patient could not have the disease and get a positive result. Specifically (recalling that conditional probabilities are obtained by multiplication),\n\n\\begin{align}\nP(+ve) = P(disease) * P(+ve\\:|\\:disease) + P(no\\:disease) * P(+ve\\:|\\:no\\:disease)\n\\end{align}\n\nLooking back at the diabetes model results from earlier, we had a sensitivity of ~87% and a specificity of ~61%. We can now obtain the probability of disease, given the disease prevalence. Let’s say that you're using this test in a different population than the test was evaluated in (often the case in the real world), and that we have a prevalence of 5%. We have,\n\n\\begin{align}\nP(disease\\:|\\:+ve) = P(+ve\\:|\\:disease)\\:*\\:\\frac{P(disease)}{P(+ve)}\n\\end{align}\n\n\\begin{align}\nP(disease\\:|\\:+ve) = P(+ve\\:|\\:disease)\\:*\\:\\frac{P(disease)}{P(disease)\\:*\\:P(+ve\\:|\\:disease)\\:+\\:no\\:disease\\:*\\:P(+ve\\:|\\:no\\:disease)}\n\\end{align}\n\n\\begin{align}\nP(disease\\:|\\:+ve) = \\frac{0.87\\:*\\:0.05}{(0.05 * 0.87) + (0.95 * 0.39)}\n\\end{align}\n\n(Note that the value of 0.39 comes from 1 - specificity)\n\n\\begin{align}\nP(disease\\:|\\:+ve) = 0.105\n\\end{align}\n\nSo, the probability of a patient having diabetes with a positive result of the test, with a disease prevalence of 5% and a test of sensitivity of 87% and specificity of 61% is **10%**.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f0127063-8af6-4bb0-89b3-f3cb88085778","_uuid":"03e3fb4416f632fc7e8cbbc7f7d668e8adf0661d"},"cell_type":"markdown","source":"<a id='ContextMattersAnExample'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"89392268-ed47-46f2-b99f-c2474835ad95","_uuid":"02fba4a321d4585e361a3a183b649a4e94d7c5d9"},"cell_type":"markdown","source":"### Context Matters - An Example","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ee727dc6-adad-4033-97c3-7cd25d459fd2","_uuid":"43668637062109084248dc15f48a6f501b3dd994"},"cell_type":"markdown","source":"These sorts of calculations are often not well understood or in the forefront of clinician's minds when diagnosing disease. In fact, there are some quite scary studies demonstrating the serious levels of error in posterior probability estimates when health professionals are presented with tests with very high levels of sensitivity and specificity, plus the widespread practice of ignoring formal Bayesian calculations$^{[19]}$. This is serious stuff, because without taking into account the context of a diagnostic test result, either properly or at all, you're left with a single piece of evidence that is impossible to interpret. \n\nFor example, imagine you have a diagnostic test for Ebola with reasonably high levels of sensitivity and specificity, and you run it on someone. You get a **positive** result. Does the person have Ebola?\n\nWhat if you'd run the test in Sierra Leone in 2015. The context suggests you've got a true positive. What about if the test had been run on someone living in a remote rural location in the highlands of Scotland? Now it's looking like a false positive. But wait a minute, it turns out that this person was just back from a voluntary medical placement in Sierra Leone. Back to true positive. Next you discover they had an experimental but highly effective Ebola vaccine last year. Now what?\n\nOr, take a more extreme example. Home pregnancy tests aren't perfect. If you tested them on thousands of men, you may get a few false-positives (I believe there is some evidence that the hormone that the test looks for, [**beta human chorionic gonadotropin (hCG)**](https://en.wikipedia.org/wiki/Human_chorionic_gonadotropin), is raised in some types of cancer$^{[20]}$). But if your aim is to answer the question 'is this person pregnant?', a positive result from the test would be dragged down to zero for a man, given the wider biologic context (setting aside [Arnold Schwarzenegger films](https://en.wikipedia.org/wiki/Junior_(1994_film)), *because the prior is zero*.\n\nThe test characteristics haven’t changed, but the context *frames* an imperfect result. How an individual does this is critical during the medical decision-making process, and in formal Bayesian contexts, this often involves elicitation.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f97d1eb1-34d7-4c4e-8d9c-8924cb903de6","_uuid":"0ab811aef53998f40b3d51ea104e9a512c95b0f0"},"cell_type":"markdown","source":"<a id='BeliefElicitation'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"fd3e109a-43f4-4253-a6d3-80a68fe059d2","_uuid":"87f69b5d948b8f93318eefa37ee5da33940ae3a4"},"cell_type":"markdown","source":"### Belief Elicitation","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"6840719c-422d-4194-8865-f25c2eaad6b0","_uuid":"561e7ae3f6a49e936db9ba62e0dc58c772385d88"},"cell_type":"markdown","source":"Elicitation is ...*\"the process of translating someone's judgement about some uncertain quantities into something useful for a model\"*$^{[21]}$ and that *\"This will typically be a probability distribution\"*.\n\nIn other words, it's translating from a doctor saying *\"I'm not sure if that patient has disease X, but I'm pretty confident that one does\"* to *\"Patient A has a prior probability of 20% and patient B has a prior probability of 90%\"*. Now, the danger here is that ten different doctors give you ten different probabilities, due to differences in knowledge, experience and personal biases. For example, one study from 1986 assessing the prior beliefs of 104 clinicians (elicited based upon reviewing patient case summaries) vs actual patient outcomes found huge variations in estimates (ranges of >90%), concluding that the subjective beliefs were largely inaccurate$^{[22]}$. There is also research showing a whole host of reasons why such subjectivity can falter, including,\n\n- ***Availability heuristic*** *(clinicians judge the likelihood of a particular diagnosis by how easily examples spring to mind)*\n- ***Anchoring heuristic*** *(physicians stick with initial impressions)*\n- ***Framing effects*** *(people make different decisions based on how information is presented)*\n- ***Blind obedience*** *(trainees stop thinking when confronted with authority)*\n- ***Premature closure*** *(when several possible options are not pursued)”* $^{[1]}$\n\nSince the time of the 1986 paper, there have been efforts to improve the elicitation methodology. In one recent review of the subject$^{[23]}$, they state that *\"'Prior belief is often a combination of fact-based knowledge with subjective impressions based on clinical experience\"* and that to answer the criticisms of introducing a subjective element, that *\"belief-elicitation methods should be valid, reliable, responsive to change, and feasible\"*. They go on to warn that *\"Threats to the reliability of an elicitation procedure include lack of understanding of the elicitation procedure, carelessness, lack of interest, and fatigue\"*.\n\nSetting aside the subjective elements of prior elicitation, one simpler and objective method is to use the prevalence on the disease in question (as mentioned previously). This, however, comes with its own problems. How do we define 'prevalence'? Is it the national prevalence? County prevalence? Prevalence of an individual hospital? What about age, sex and clinical signs? Is it right to use the same prevalence for a 10-year-old and an 80-year-old? Probably not. In one review of the ways in which disease rates in populations can be quantified$^{[24]}$, they discuss the **point-prevalence** (a snap-shop of disease rates now), and **period-prevalence** (the overall prevalence over, say, a 12 month period), going on to discuss **'crude' prevalence** (which is the gross, population level estimate) and **'specific'** estimates (breaking down by age and sex, for example). An example of this can be found in a 2017 study$^{[25]}$ of crude and specific prevalence of diabetes, where they found that the crude prevalence was 1.13 per 1000, but much higher at 3.94 for those aged 70-79.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"deec4fdb-ac46-4ece-aedd-300fa0d87473","_uuid":"eb1ca94d2d59f67234f35d826ab5f58c2dda9e05"},"cell_type":"markdown","source":"<a id='FromPriortoPosteriorProbabilities'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"835928b9-3a30-43d4-83a6-a0a41aac4abb","_uuid":"e2caf862ff81ff256eebf3385af98678bc630d64"},"cell_type":"markdown","source":"### From Prior to Posterior Probabilities","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"5c66b1bd-970d-4cbf-b0f5-ffd1f26552cc","_uuid":"b498a3875d83a3e957d0cfad8076664367967976"},"cell_type":"markdown","source":"So, how do you go from a prior probability to a posterior one, via a diagnostic test? The answer is to use something called [**likelihood ratios**](https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing), and these have the key feature that they incorporate both the sensitivity and the specificity. Indeed, a major criticism of diagnostic testing is when people try to rule-in or rule-out diseases using only a single metric.\n\nFor example, it is often seen in diagnostic literature that a high sensitivity test is very useful for ruling-out a disease. This is because a high-sensitivity test 'wants' to give a positive answer, meaning it will do so with only a small amount of evidence. Therefore, if you get a negative result with such a test, the logic is that the evidence for a positive result is extremely small. The same (but reverse) logic holds for ruling-in a disease.\n\nHowever, what if your super-sensitive test has a very poor specificity? Say, a sensitivity of 98% and a specificity of 10%. It could be argued at this point that you're not that much further from just calling every case you see a positive (which would give you a sensitivity of 100% and specificity of 0%). In other words, your test's overall predictive ability is poor. A number of articles/papers are available that explain the consequences of such issues$^{[26,27]}$\n\nLikelihood ratios are calculated as follows,\n\n\\begin{align}\nPositive\\:Likelihood\\:Ratio = \\frac{Sensitivity}{(1-Specificity)}\n\\end{align}\n\n\\begin{align}\nNegative\\:Likelihood\\:Ratio = \\frac{1-Sensitivity}{(Specificity)}\n\\end{align}\n\nTo go from a prior to a posterior using these ratios, people have historically used something called a [**Fagan Nonogram**](http://www.pmean.com/definitions/fagan.htm). This is a graphical tool that allows the user to draw a line from the prior probability through a likelihood ratio, in order to reach a posterior probability. However, given a computer, it's much easier to just computer the result. For this, we use the following equations,\n\n\\begin{align}\nPrior\\:odds = \\frac{prior\\:probability}{(1-prior\\:probability)}\n\\end{align}\n\n\\begin{align}\nPosterior\\:odds = Prior\\:odds * Likelihood\\:Ratio\n\\end{align}\n\n\\begin{align}\nPosterior\\:probability = \\frac{Posterior\\:odds}{(Posterior\\:odds + 1)}\n\\end{align}\n\n\nLet's put that into a function,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"8fa75e6a-1905-4ef2-a379-bcbdfd6d5f90","_uuid":"c6d272156364b293fbca71699ff73987735c392c","collapsed":true,"trusted":true},"cell_type":"code","source":"def diagnostic_posterior(prior,sens,spec):\n    lr_pos = sens / (1 - spec) #Positive likelihood ratio\n    lr_neg = (1 - sens) / spec #Negative likelihood ratio\n    \n    pre_odds = prior / (1-prior) #Prior odds\n    post_odds_pos = pre_odds * lr_pos #Positive posterior odds\n    post_odds_neg = pre_odds * lr_neg #Negative posterior odds\n    post_pos = post_odds_pos / (1+post_odds_pos) #Positive posterior probability\n    post_neg = post_odds_neg / (1+post_odds_neg) #Negative posterior probability\n    \n    return(post_pos, post_neg)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c0d092c-bead-4988-a4c2-6ffdd55b85b9","_uuid":"4542b61eb10fdfb740157081436ac8ab3e5294cd"},"cell_type":"markdown","source":"Note that you can get a sense of how much your likelihood ratios will affect the posterior probability from their values. For example, a likelihood ratio of 1 won't affect it at all, a likelihood ratio of 0.1 will lead to a large decrease, and a likelihood ratio of 10 will lead to a large increase. In the breast cancer data above, a quick model gave us a sensitivity of ~0.88 and a specificity of ~0.93. Let's see what the likelihood ratios would be,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f8d05be9-7de9-49e0-bf22-7f55ecb879fd","_uuid":"8925cd42b4a5df970eb98a481f397a84b9cb5d49","trusted":true},"cell_type":"code","source":"lr_pos = 0.88 / (1 - 0.93) #Positive likelihood ratio\nlr_neg = (1 - 0.88) / 0.93 #Negative likelihood ratio\nprint(\"The positive and negative likelihood ratios are %s, and %s, respectively\" % (round(lr_pos,2), round(lr_neg,2)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ad0e84d5-552c-488d-b9fa-36bedd877fdc","_uuid":"ee858d4397484cf44af81ac00d6b9ac69376b002"},"cell_type":"markdown","source":"We can now use the above function get posterior probabilities, which we'll do with a new dataset below.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"66a9a916-dde8-481b-ad11-eb063bd265ba","_uuid":"3b1f71712ff5c31167ab5f8ae67073ed0cc9e83c"},"cell_type":"markdown","source":"Before we do, a quick warning. Often, diagnostic tests are done sequentially (using the posterior probability of one test as the prior probability of the next). If the first test in a chain of tests is a quick, cheap test used for **triaging**, and the second test is a more accurate version, that's fine. For example, you use a high sensitivity test to quickly detect as many positives (including some false positives) from a group of patients, and then you can perform a potentially more expensive test on those flagged.\n\nIf, however, you wish to update your posterior probability through-out a chain of tests, you need to be very careful that the tests are **conditionally independent**. For example, let's say you assign a prior probability of a patient having a certain disease at 10%. You then run a test that comes back positive, and you end up with a posterior of 50%. It would clearly be crazy to rerun the test, get another positive, and update your probability again, but this is exactly what you're doing if a second test is effectively mimicking the first.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"679ea58f-9095-4fe3-bfba-3063ae13922c","_uuid":"fc460c8bd3729b62a068c5f0a30a81f11565c8be"},"cell_type":"markdown","source":"With all of this in mind, let's generate some posterior probabilities. Looking through the Kaggle datasets led me to a couple that could illuminate this point. These are the 'Health Analytics' and the 'Health Nutrition and Population Statistics' datasets.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"024850ef-ba95-478e-bb7b-769b6d76b08b","_uuid":"c2805ec93ee7414d1d97f32b7b7066166ef9d94c"},"cell_type":"markdown","source":"#### Health Analytics Dataset","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f6d66837-de0b-4496-943e-c7c20f83a9b8","_uuid":"85d6a4f37e4b508a8baa2b8232b4ede95d8ba0f0"},"cell_type":"markdown","source":"This data stems from an annual health survey established in 2005 by the National Commission of Population, India, with the goal of providing data to improve district-level planning.\n\nLet's take a look,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"354f2ae3-4ba5-4d01-83d2-60ec7eaa6175","_uuid":"fc144e82654ab11f73734033f1003749ceeccec8","collapsed":true,"trusted":true},"cell_type":"code","source":"health = pd.read_csv('../input/key-indicators-of-annual-health-survey/Key_indicator_statewise.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"77a428e8-4095-47fe-97c4-b5f5ab16c2f4","_uuid":"3d3ac4003e979721049bba4208283a529da6d8a0","trusted":true},"cell_type":"code","source":"health.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"52d3cb79-9b86-45c4-88e0-695d05c7af68","_uuid":"8bcd385e6f00bcfe0780e6ab9fe131fa57a2542c"},"cell_type":"markdown","source":"Let's use the data relating to acute respiratory infections,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"6191ccd2-4c7d-4b40-a5b0-618ff8266e39","_uuid":"0d2aa5a82b7b7fa34159c15c12da8ec019d1b405","collapsed":true,"trusted":true},"cell_type":"code","source":"health_sub = health.loc[:,['State_Name', 'UU_Children_Suffering_From_Acute_Respiratory_Infection_Total', 'UU_Children_Suffering_From_Acute_Respiratory_Infection_Rural', 'UU_Children_Suffering_From_Acute_Respiratory_Infection_Urban']]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7b7ed5b3-7ccd-48f1-8c6d-5d27b3e690b7","_uuid":"b191c85b55d0ae1cbdc7f987b6eaed9b08120f64","trusted":true},"cell_type":"code","source":"health_sub","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"28eeb9b3-f6e9-4314-8ea1-2c7c60f5e789","_uuid":"1b0700b23ebb18b0d4dc7c62b9154ff893b27b66"},"cell_type":"markdown","source":"So, the context here is that if a child was taken to a clinician with breathing difficulties, an acute respiratory infection might be suspected. Let's say a test is available for such a condition with a particular sensitivity and specificity. We could use the data here as a prior probability, and what's interesting is that we have specific values for different states and different environments. For example, take a look at the minimum value in the table,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"25744b11-876b-4581-8f6c-8f8d43a12f0f","_uuid":"aa89057785cac0e6193eabb36ca93472ed9805de","trusted":true},"cell_type":"code","source":"health_sub.loc[health_sub['UU_Children_Suffering_From_Acute_Respiratory_Infection_Total'].idxmin()]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b176b68c-6764-4e04-9e06-8d09856a81c9","_uuid":"7663ffcfce509fba8d7f3ab28d3efce6dad4937b"},"cell_type":"markdown","source":"And the maximum,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"6cbef160-a89d-42aa-b489-8e3cafddda83","_uuid":"393af475f75b172b9c71f24c49a0e1c20550e9a4","trusted":true},"cell_type":"code","source":"health_sub.loc[health_sub['UU_Children_Suffering_From_Acute_Respiratory_Infection_Total'].idxmax()]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6ac90066-5a80-42b5-bcf7-ecc0a47d25ee","_uuid":"58beec1d166cd206d1323e88ccb810c5308e77fc"},"cell_type":"markdown","source":"So, it could be argued that a child with suspected acute respiratory infection in Bihar, living in a rural area has a prior of 27.9%, and a child from Uttarakhand also living in a rural area has a prior of 10.96%. These differences would matter!\n\nLet's use a different dataset to perform some calculations,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"93237b7c-b17d-45cb-ad27-2912f0b7868f","_uuid":"4f6c2282d8eae202fbda5e78f7906d3a1b668f8e"},"cell_type":"markdown","source":"#### Health Nutrition and Population Statistics Dataset","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"d3e21ffc-7b53-4ca9-9a61-0db7a56fbcc8","_uuid":"96bf739dd7251d1d12b2bb771fb606b5d19a9bb9"},"cell_type":"markdown","source":"Collated by the WorldBank, this dataset provides information on a large range of health-related topics. The quote the [official website](https://datacatalog.worldbank.org/dataset/health-nutrition-and-population-statistics), *\"HealthStats provides key health, nutrition and population statistics gathered from a variety of international sources. Themes include population dynamics, nutrition, reproductive health, health financing, medical resources and usage, immunization, infectious diseases, HIV/AIDS, DALY, population projections and lending. HealthStats also includes health, nutrition and population statistics by wealth quintiles\"*","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"c2ad0585-d673-4630-ba28-cad0ba506971","_uuid":"78e5e561ca05dd6328aa1f7cb57781336a41a6cb","collapsed":true,"trusted":true},"cell_type":"code","source":"global_health = pd.read_csv('../input/health-nutrition-and-population-statistics/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6e64516c-8693-4a4f-9257-5b1ea5cc10ea","_uuid":"a05279ec0088cebeb4f655df1fde2ac97b91f152","trusted":true,"collapsed":true},"cell_type":"code","source":"global_health.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"996d38c3-5b69-4fae-a6b2-cf332d02f8dc","_uuid":"c3dbd2b5767b6398bb42b2d243a8e2bf4b56036b"},"cell_type":"markdown","source":"Let's use data on HIV prevalence,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"fe78de09-a247-451b-bcc2-31c6116fbe2d","_uuid":"9046c8773f9ec69ae0fbe2f31063e4faf61568dc","collapsed":true,"trusted":true},"cell_type":"code","source":"global_health_sub = global_health[global_health['Indicator Name'].str.contains('Prevalence of HIV')]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"14f1db20-7ab9-4d70-91de-3014f7b5697e","_uuid":"36d5a1b28cc51cb8a17df7e96db3ecdde038fc99","collapsed":true,"trusted":true},"cell_type":"code","source":"global_health_sub = global_health_sub.loc[:,('Country Name', 'Indicator Name', '2005')]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"726074c3-b828-4bf4-82cc-ab36dafcbcbd","_uuid":"9c3f2fb4b8198a25363dea0fed95e2ca872ecd87","collapsed":true,"trusted":true},"cell_type":"code","source":"global_health_sub = global_health_sub.dropna(subset = ['2005'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9fa348d7-cf4d-41d5-a25a-868c4471636c","_uuid":"d8b8701e6f14a1eed212ef8cd8aac9a5506eb208","trusted":true,"collapsed":true},"cell_type":"code","source":"global_health_sub.sort_values(['2005']).head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bf81a843-eaec-4d3d-925f-529be2c2d4dc","_uuid":"941dd808dd0b7173ee19cf9bb5958d87c7e92d3b","trusted":true,"collapsed":true},"cell_type":"code","source":"global_health_sub.sort_values(['2005']).tail()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3427dc01-710c-478c-a7fc-25e9f867b32d","_uuid":"6b0f6ace7999eba14489e96fffc6e21f86fe3f56"},"cell_type":"markdown","source":"The data for different countries,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ac2c15b6-77a4-44e9-b820-5c9923d4409f","_uuid":"dc99f1c19a6beaebd4e111d2975c49eb49538e29","trusted":true,"collapsed":true},"cell_type":"code","source":"global_health_sub[global_health_sub['Country Name'] == 'Swaziland']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4ab7216f-4ac4-4755-9d6d-4ca13abc11b2","_uuid":"615f13ce0bc1595bf0d4202d225083ea1de0f230","trusted":true,"collapsed":true},"cell_type":"code","source":"global_health_sub[global_health_sub['Country Name'] == 'Belarus']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"494dec00-31ee-4699-9cfe-731847d54c68","_uuid":"ba3931ebd9b73c44928242892eb704ba439ceadb"},"cell_type":"markdown","source":"So, let's say we have a quick, cheap, [point-of-care](https://en.wikipedia.org/wiki/Point-of-care_testing) HIV test that works on a single drop of blood and gives a YES/NO answer in 10 minutes (this would probably be a [lateral flow device](https://en.wikipedia.org/wiki/Lateral_flow_test), like with a home pregnancy test). The test has a sensitivity and specificity of 99%, and you run the test on four different people,\n\n- A 20 year old man from Swaziland\n- A 20 year old woman from Swaziland\n- A 20 year old man from Belarus\n- A 20 year old woman from Belarus\n\nAll four test results are 'YES' (or positive for HIV). What is the probability, based upon the data we have, that they've got HIV? Let's take a look,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"fc469b33-eb4c-47ad-b187-b0b8f5ada7e2","_uuid":"42f902ac43f7dcf3aacbb6483db70ce7b680cbce","trusted":true,"collapsed":true},"cell_type":"code","source":"print(\"A 20 year old man from Swaziland probability is {:0.2f}\".format(diagnostic_posterior(0.181,0.99,0.99)[0]))\nprint(\"A 20 year old woman from Swaziland probability is {:0.2f}\".format(diagnostic_posterior(0.067,0.99,0.99)[0]))\nprint(\"A 20 year old man from Belarus probability is {:0.2f}\".format(diagnostic_posterior(0.001,0.99,0.99)[0]))\nprint(\"A 20 year old woman from Belarus probability is {:0.2f}\".format(diagnostic_posterior(0.001,0.99,0.99)[0]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2b28588d-8295-44ea-9dac-f891e55ff1b1","_uuid":"60759cdf045ddd6519191f856fd1e93341069c17"},"cell_type":"markdown","source":"So, the exact same test giving the exact same result could mean the person has a **9%** or **96%** chance of having HIV. **Context matters!**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f92d698b-102d-4b48-9f72-8d6b5c608e29","_uuid":"25d7ebee8e657c958069ddb324403f4c262ddec8"},"cell_type":"markdown","source":"Let's generate the posterior probability for this imaginary test at all prevalences,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"17c5e35e-bcd9-42a3-b927-ecf4f847ba54","_uuid":"08d100a48f70329f1981a887da1b0ed527940753","collapsed":true,"trusted":true},"cell_type":"code","source":"post = list()\nprev_options = np.arange(0.0, 1.0, 0.01)\n\nfor i in prev_options:\n    post_temp = diagnostic_posterior(i,0.99,0.99)[0]\n    post.append(post_temp)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"038087c3-4cbf-4815-bbcc-6bf93623751e","_uuid":"cfacda155309eff9e21cda677f589b8b4472c659"},"cell_type":"markdown","source":"Then plot the results, along with the two prevalences highlighted above,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"8c9243e1-39a4-45b4-94f2-7268ccfc7f93","_uuid":"6e39e9516f73d228162325a7fbaf67f88a81019a","trusted":true,"collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(prev_options, post)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('Prevalence vs Posterior Probability (sens/spec = 0.99)')\nplt.xlabel('Prevalence')\nplt.ylabel('Posterior Probability')\nplt.axvline(x=0.181, color='r')\nplt.axvline(x=0.001, color='r')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b4cabce6-b43e-4a64-9783-ef519ff65d4c","_uuid":"a4078394a98a35eb25b5a90672cf757bd6c2b910"},"cell_type":"markdown","source":"As you can see, at such high sensitivity and specificity, the posterior probability jumps very quickly, meaning that you only need a small prior probability (disease prevalence here) for the test to give a high probability. If the sensitivity and specificity were lower (say, both 0.80), the rise would be more gradual,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"a07a8eb0-e033-4c25-97d9-95df5101bab6","_uuid":"e5569258c494c79c5ae630f8c61dca7b3820e4e9","trusted":true,"collapsed":true},"cell_type":"code","source":"post = list()\nprev_options = np.arange(0.0, 1.0, 0.01)\n\nfor i in prev_options:\n    post_temp = diagnostic_posterior(i,0.80,0.80)[0]\n    post.append(post_temp)\n    \nfig, ax = plt.subplots()\nax.plot(prev_options, post)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('Prevalence vs Posterior Probability (sens/spec = 0.80)')\nplt.xlabel('Prevalence')\nplt.ylabel('Posterior Probability')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"050acf79-28cc-42c1-88b0-feea60f386b6","_uuid":"f2847e8f29fef98dfa2e0e21c35fa5213da123e4"},"cell_type":"markdown","source":"<a id='TreatmentThresholds'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"e14d1ba2-e7a3-4ee4-aa12-a62b4de0b4ec","_uuid":"d025bb66fbb034ecb5fb6e34fdce40ca211b33ae"},"cell_type":"markdown","source":"### Treatment Thresholds","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"6e461c9c-0bce-4859-998d-d3aadddc7a4d","_uuid":"6dd156bf7c297dea255c12c143b7a5881262d549"},"cell_type":"markdown","source":"***\"The art of medicine consists in amusing the patient while nature cures the disease\"*** - Voltaire","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"3b803ef3-0ea2-4c40-8ddb-8d3f05c08404","_uuid":"8362f6dfcac0f1124fbeab80873147d0abd5084e"},"cell_type":"markdown","source":"There is one more consequence of all this, which, if used more by medical professionals could save quite a lot of money. The idea is that of treatment thresholds, which are informal levels above which the clinician would take a certain course of action$^{[28]}$. For example, let's say that a clinician is about to run a diagnostic test for a certain disease, and it costs £50. The sensitivity of the test is 92% and the specificity is 85%, and the threshold for treatment, i.e. the posterior probability above which a certain drug will be prescribed, is 90%. Now let's say the prior probability is estimated to be just 1%. Before the test is run, let's see what the posterior probability will be *if we get a positive result*,","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"82734b54-b645-484a-b5ab-45ba4ffbc9a2","_uuid":"bece6524e0ee52544bc836099a77458df22c7626","trusted":true,"collapsed":true},"cell_type":"code","source":"diagnostic_posterior(0.01,0.92,0.85)[0]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1b8b682-c53f-47c2-bf34-5b7694dfeccc","_uuid":"e4dbd6a59697fa97bfafbda2aa0b8b76d492da1a"},"cell_type":"markdown","source":"Just under 6%. No-where near the informal 90% that the clinician had in mind for starting the course of treatment. Therefore, *there is absolutely no point running the test*, as it's result, whether negative or positive, *will not change the course of action*. How many tests are run globally, every day, that fit this description? I dread to think! The takeaway here is that diagnostic tests should only be used when their outcome could alter the **management of the patient**.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"7974e67a-1dcb-49c1-a81d-d68fa00d1066","_uuid":"5d4d9db676bfd3d3d0ef9149724349eac4f482ac"},"cell_type":"markdown","source":"<a id='Useintherealworld'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"63523f1c-eece-4295-bb69-819a493caa56","_uuid":"1651b3514e2871ebdc6889a36c6857d8d68b1c0f"},"cell_type":"markdown","source":"### Use in the Real World","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"681abc95-7389-4ecd-ba93-8f60e7c13dda","_uuid":"c12be78244cf6e33bbaf4770157b70ed0a4a0904"},"cell_type":"markdown","source":"The application of Bayesian statistics to diagnostic testing is widespread in the literature. Almost all have a common theme; They begin by criticising the current, common application of diagnostic test results, and then propose using Bayesian statistics instead$^{[29-40]}$. All the arguments and explanations above can be found repeated in these papers.\n\nThe elicitation of prior probabilities and their effectiveness is a large area of research$^{[41-47]}$, demonstrating that the establishment of pre-test probabilities can potentially involve immense amounts of work. It should be noted, however, that often this work is focussed upon establishing **prior distributions** (i.e. not just single values) for every term in a complex statistical model. These priors are commonly described using [beta distributions](https://en.wikipedia.org/wiki/Beta_distribution). The posterior probabilities are then determined using advanced computational techniques such as MCMC. This is a level of detail and technicality beyond what is being proposed here.\n\nA number of papers exist that employ Bayesian techniques in the manner outlined above. For example, in a paper by Cochon et al$^{[48]}$, the diagnostic value of lactate, [procalcitonin](https://en.wikipedia.org/wiki/Procalcitonin) (PCT) and [C-reactive protein](https://en.wikipedia.org/wiki/C-reactive_protein) (CRP) are assessed for the diagnosis of [sepsis](https://en.wikipedia.org/wiki/Sepsis). However, rather than taking the results of these tests in isolation, the results are combined with prior probabilities, along with each test’s positive and negative likelihood ratios. Interestingly, rather than using a subjective prior, the patients in the study were stratified into three groups (low risk, medium risk and high risk) using the **Mortality in Emergency Department (MEDS) risk score** $^{[49,50]}$. This is a system based upon a series of risk factors, including age, platelet count and mental state. Their conclusion was that PCT offered the highest relative gain from prior to posterior probabilities (i.e. the highest positive likelihood ratio).\n\nIn a related paper, Cochon$^{[51]}$ et al applied a similar tactic to assess PCT and lactate for the prediction of ICU admission of pneumonia patients. Here they employed the **CURB 65 scoring system** for the patient stratification$^{[52,53]}$. This system is based upon factors such as mental state, respiratory rate and age.\n\nIn a paper by Lu et al$^{[54]}$, both machine learning and Bayesian methods were employed to predict rotator cuff tears (a common cause of shoulder diseases). In this paper, three different algorithms were developed based upon 16 attributes of 169 patients (evaluated using 10-fold [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)). The results from the best performing algorithm where then used with subjective prior probabilities (via a Fagan nonogram) to give posterior probabilities for each patient (the true outcome for each patient was known from consequent MRIs scans).","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f96cfede-4f36-4def-a63e-f358e910d6d2","_uuid":"bf4238ac5064b8634f09eeaa3706138f0ca9719b"},"cell_type":"markdown","source":"<a id='ClosingThoughts'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"93282637-cabd-4c42-9d53-0178f6a78553","_uuid":"a26d2c299f1f890382cab909c30b8f7f34fa0b0e"},"cell_type":"markdown","source":"### Closing Thoughts","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"4603059a-d993-4d0d-9c1f-417ef77f8e91","_uuid":"ecf748768070ef4c8777bcb54690e21baa260c76"},"cell_type":"markdown","source":"I began this kernel with a quote from the doctor,\n\n***“The results are back. You’ve got a 1 in 64 chance”***\n\nAnd at that time, the response from myself and my relative were extremely negative, and I seem to recall that we didn't question the result at all. If and when I find myself in a similar situation, I would be wise to ask some of the following,\n\n- What is the sensitivity and specificity of the test?\n- How were those values determined?\n- What was the sample size?\n- What are the confidence interval ranges?\n- Was the population used for the evaluation comparable to real-world use?\n- Are you sure the study was free of bias?\n- Have you put my test results in the context of a Bayesian prior?\n- If so, what evidence do you have for how you determined the prior?”\n\nVery often, one if not several of the above questions will have some very shaky answers. So, the take-home message with a diagnostic test result is ... **don't panic**. Yes, it *could* be correct. It might even *probably* be correct. But these tests aren't perfect, *especially* if relatively unsophisticated and *especially* if taken without context....\n\n\n\n\n... probably :-)\n\n\n\n","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"83277b02-0851-4b25-ad1f-f0befee3e71d","_uuid":"2bb729e653758f00adc8ec8b97e83d993492b36f"},"cell_type":"markdown","source":"<a id='References'></a>","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"6a0db41a-da9a-46a9-8151-aea99ae973a6","_uuid":"5de98d29cd643b322cc2365ef85cf3ad46d52f81"},"cell_type":"markdown","source":"### References\n\n[1] Jacob, K. S. [\"The challenge of medical diagnosis: A primer on principles, probability, process and pitfalls.\"](https://www.ncbi.nlm.nih.gov/pubmed/26219318) (2015).\n\n[2] Powers, David MW. [\"The problem of area under the curve.\"](http://ieeexplore.ieee.org/document/6221710/) Information Science and Technology (ICIST), 2012 International Conference on. IEEE, 2012.\n\n[3] [The Area Under an ROC Curve](http://gim.unmc.edu/dxtests/roc3.htm)\n\n[4] [What causes high bilirubin levels?](https://www.medicalnewstoday.com/articles/315086.php)\n\n[5] [Youden's J statistic](https://en.wikipedia.org/wiki/Youden%27s_J_statistic)\n\n[6] Hajian-Tilaki, Karimollah. [\"Receiver operating characteristic (ROC) curve analysis for medical diagnostic test evaluation.\"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3755824/) Caspian journal of internal medicine 4.2 (2013): 627.\n\n[7] Akobeng, Anthony K. [\"Understanding diagnostic tests 3: receiver operating characteristic curves.\"](https://www.ncbi.nlm.nih.gov/pubmed/17376185) Acta paediatrica 96.5 (2007): 644-647.\n\n[8] Kumar, Rajeev, and Abhaya Indrayan. [\"Receiver operating characteristic (ROC) curve for medical researchers.\"](https://www.ncbi.nlm.nih.gov/pubmed/21532099) Indian pediatrics 48.4 (2011): 277-287.\n\n[9] Hawkins, Robert C. [\"The evidence based medicine approach to diagnostic testing: practicalities and limitations.\"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1252824/) *Clin Biochem Rev* 26.2 (2005): 7-18.\n\n[10] Cook, Chad, Joshua Cleland, and Peter Huijbregts. [\"Creation and critique of studies of diagnostic accuracy: use of the STARD and QUADAS methodological quality assessment tools.\"](http://www.tandfonline.com/doi/abs/10.1179/106698107790819945) *Journal of Manual & Manipulative Therapy* 15.2 (2007): 93-102.\n\n[11] Pearl, William S. [\"A hierarchical outcomes approach to test assessment.\"](http://www.annemergmed.com/article/S0196-0644(99)70421-X/abstract) *Annals of emergency medicine* 33.1 (1999): 77-84.\n\n[12] Hegedus, Eric J., and Ben Stern. [\"Beyond SpPIN and SnNOUT: considerations with dichotomous tests during assessment of diagnostic accuracy.\"](http://www.tandfonline.com/doi/abs/10.1179/jmt.2009.17.1.1E) *Journal of Manual & Manipulative Therapy* 17.1 (2009): 1E-5E.\n\n[13] Pewsner, Daniel, et al. [\"Ruling a diagnosis in or out with “SpPIn” and “SnNOut”: a note of caution.\"](http://www.bmj.com/content/329/7459/209.short) *Bmj* 329.7459 (2004): 209-213.\n\n[14] Roever, L. [\"Types of Bias in Studies of Diagnostic Test Accuracy.\"](https://www.omicsonline.org/open-access/types-of-bias-in-studies-of-diagnostic-test-accuracy-ebmp-1000e113.php?aid=70361) Evidence Based Medicine and Practice Open Access Journal: 1000e113. doi 10 (2015): 2.\n\n[15] Gill, Christopher J., Lora Sabin, and Christopher H. Schmid. [\"Why clinicians are natural bayesians.\"](http://www.bmj.com/content/330/7499/1080.short) Bmj 330.7499 (2005): 1080-1083.\n\n[16] Reid, M. Carrington, David A. Lane, and Alvan R. Feinstein. [\"Academic Calculations versus Clinical Judgments: Practicing Physicians’ Use of Quantitative Measures of Test Accuracy 1.\"](http://www.amjmed.com/article/S0002-9343(98)00054-0/pdf) The American journal of medicine 104.4 (1998): 374-380.\n\n[17] Whiting, Penny F., et al. [\"How well do health professionals interpret diagnostic information? A systematic review.\"](http://bmjopen.bmj.com/content/5/7/e008155) BMJ open 5.7 (2015): e008155.\n\n[18] The Advanced Handbook of Methods in Evidence Based Healthcare, Stevens, A et al. Chapter 16 – Bayesian Methods\n\n[19] Agoritsas, Thomas, et al. [\"Does prevalence matter to physicians in estimating post-test probability of disease? A randomized trial.\"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3055966/) Journal of general internal medicine 26.4 (2011): 373-378.\n\n[20] [Home pregnancy tests may detect men's cancer](http://thechart.blogs.cnn.com/2012/11/08/home-pregnancy-tests-may-detect-mens-cancer/)\n\n[21] Gosling, John Paul. [\"Methods for eliciting expert opinion to inform health technology assessment.\"](https://pdfs.semanticscholar.org/38eb/a762cdaf5d6dae2fee2063bf776d5facec5b.pdf) Vignette Commissioned by the MRC Methodology Advisory Group. Medical Research Council (MRC) and National Institure for Health Research (NIHR) (2014).\n\n[22] Dolan, James G., Donald R. Bordley, and Alvin I. Mushlin. [\"An Evaluation of Clinicians' Subjective Prior Probability Estimates.\"](https://www.ncbi.nlm.nih.gov/pubmed/3773651) Medical Decision Making 6.4 (1986): 216-223.\n\n[23] Johnson, Sindhu R., et al. [\"Methods to elicit beliefs for Bayesian priors: a systematic review.\"](http://www.jclinepi.com/article/S0895-4356(09)00175-9/pdf) Journal of clinical epidemiology 63.4 (2010): 355-369.\n\n[24] [Chapter 2. Quantifying disease in populations](http://www.bmj.com/about-bmj/resources-readers/publications/epidemiology-uninitiated/2-quantifying-disease-populations) *Bjm*\n\n[25] - Pendharkar, Sayali A., Juby Mathew, and Maxim S. Petrov. [\"Age-and sex-specific prevalence of diabetes associated with diseases of the exocrine pancreas: a population-based study.\"](https://www.ncbi.nlm.nih.gov/pubmed/28110921) Digestive and Liver Disease 49.5 (2017): 540-544.\n\n[26] - Pewsner, Daniel, et al. [\"Ruling a diagnosis in or out with “SpPIn” and “SnNOut”: a note of caution.\"](http://www.bmj.com/content/329/7459/209) Bmj 329.7459 (2004): 209-213.\n\n[27] - Hegedus, Eric J., and Ben Stern. [\"Beyond SpPIN and SnNOUT: considerations with dichotomous tests during assessment of diagnostic accuracy.\"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2704350/) Journal of Manual & Manipulative Therapy 17.1 (2009): 1E-5E.\n\n[28] - [Bayes, Medical Diagnostics, and Nomograms](https://www.youtube.com/watch?v=7VTQ1glcXYg&feature=youtu.be)\n\n[29] - Homwong, Nitipong, et al. [\"A Bayesian approach for inductive reasoning to clinical veterinary medicine: The math of experience.\"](http://www.academicjournals.org/journal/JVMAH/article-abstract/C0C1ED055220) Journal of Veterinary Medicine and Animal Health 7.10 (2015): 308-316.\n\n[30] - Lesaffre, Emmanuel, Niko Speybroeck, and Dirk Berkvens. [\"Bayes and diagnostic testing.\"](http://www.cbra.be/publications/Lesaffre2007.pdf) Veterinary parasitology 148.1 (2007): 58-61.\n\n[31] - L ESPALLARDO, Noel. [\"Decisions on diagnosis in family practice: Use of sensitivity, specificity, predictive values and likelihood ratios.\"](http://onlinelibrary.wiley.com/doi/10.1111/j.1444-1683.2003.00095.x/abstract) Asia Pacific Family Medicine 2.4 (2003): 229-232.\n\n[32] - Marasco, Joe, Ron Doerfler, and Leif Roschier. [\"Doc, what are my chances.\"](http://www.myreckonings.com/modernnomograms/Doc_What_Are_My_Chances_UMAP_32-4-2011.pdf) UMAP Journal 32 (2011): 279-298.\n\n[33] - Petrie, A., J. S. Bulman, and J. F. Osborn. [\"Further statistics in dentistry Part 9: Bayesian statistics.\"](https://www.nature.com/articles/4809892) British dental journal 194.3 (2003): 129-134.\n\n[34] - Brown, Michael D., and Mathew J. Reeves. [\"Interval likelihood ratios: another advantage for the evidence-based diagnostician.\"](http://www.annemergmed.com/article/S0196-0644(03)00401-3/abstract) Annals of emergency medicine 42.2 (2003): 292-297.\n\n[35] - Grimes, David A., and Kenneth F. Schulz. [\"Refining clinical diagnosis with likelihood ratios.\"](https://www.ncbi.nlm.nih.gov/pubmed/15850636) The Lancet 365.9469 (2005): 1500-1505.\n\n[36] - McGee, Steven. [\"Simplifying likelihood ratios.\"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1495095/) Journal of general internal medicine 17.8 (2002): 647-650.\n\n[37] - Van den Ende, Jef, et al. [\"The trouble with likelihood ratios.\"](http://www.thelancet.com/journals/lancet/article/PIIS0140-6736(05)67096-1/fulltext) The Lancet 366.9485 (2005): 548.\n\n[38] - Caraguel, Charles GB, and Raphaël Vanderstichel. [\"The two-step Fagan's nomogram: ad hoc interpretation of a diagnostic test result without calculation.\"](http://ebm.bmj.com/content/18/4/125) Evidence Based Medicine 18.4 (2013): 125-128.\n\n[39] - Gardner, I. A. [\"The utility of Bayes' theorem and Bayesian inference in veterinary clinical practice and research.\"](https://www.ncbi.nlm.nih.gov/pubmed/12537141) Australian veterinary journal 80.12 (2002): 758-761.\n\n[40] - Paulo, S., et al. [\"Diagnostic testing, pre-and post-test probabilities, and their use in clinical practice.\"](https://www.ncbi.nlm.nih.gov/pubmed/15587576) Revista portuguesa de cardiologia: orgao oficial da Sociedade Portuguesa de Cardiologia= Portuguese journal of cardiology: an official journal of the Portuguese Society of Cardiology 23.9 (2004): 1187-1198.\n\n[41] - Herrle, Scott R., et al. [\"Bayes’ theorem and the physical examination: probability assessment and diagnostic decision-making.\"](https://www.ncbi.nlm.nih.gov/pubmed/21436660) Academic medicine: journal of the Association of American Medical Colleges 86.5 (2011): 618.\n\n[42] - Houben, Paul HH, et al. [\"Pretest expectations strongly influence interpretation of abnormal laboratory results and further management.\"](https://www.ncbi.nlm.nih.gov/pubmed/20158908) BMC family practice 11.1 (2010): 13.\n\n[43] - Lyman, Gary H., and Lodovico Balducci. [\"The effect of changing disease risk on clinical reasoning.\"](https://www.ncbi.nlm.nih.gov/pubmed/7996291) Journal of general internal medicine 9.9 (1994): 488-495.\n\n[44] - Grigore, Bogdan, et al. [\"A comparison of two methods for expert elicitation in health technology assessments.\"](https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-016-0186-3) BMC Medical Research Methodology 16.1 (2016): 85.\n\n[45] - [Methodology for Eliciting Expert Opinion](https://www.mrc.ac.uk/funding/how-we-fund-research/highlight-notices/methodology-for-eliciting-expert-opinion/)\n\n[46] - Garthwaite, Paul H., Joseph B. Kadane, and Anthony O'Hagan. [\"Statistical methods for eliciting probability distributions.\"](http://www.tandfonline.com/doi/abs/10.1198/016214505000000105) Journal of the American Statistical Association 100.470 (2005): 680-701.\n\n[47] - Hampson, Lisa V., et al. [\"Elicitation of expert prior opinion: application to the MYPAN trial in childhood polyarteritis nodosa.\"](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0120981) PloS one 10.3 (2015): e0120981.\n\n[48] - Cochon, Laila, et al. [\"Acute Care Diagnostic Collaboration: Bayesian modeling comparative diagnostic assessment of lactate, procalcitonin and CRP in risk stratified population by Mortality in Emergency Department (MEDS) score.\"](https://www.ncbi.nlm.nih.gov/pubmed/28040383) The American Journal of Emergency Medicine (2016).\n\n[49] - Shapiro, Nathan I., et al. [\"Mortality in Emergency Department Sepsis (MEDS) score: a prospectively derived and validated clinical prediction rule.\"](https://www.ncbi.nlm.nih.gov/pubmed/12626967) Critical care medicine 31.3 (2003): 670-675.\n\n[50] - [Mortality in Emergency Department Sepsis (MEDS) score](http://emcalculator.com/meds)\n\n[51] - Cochon, L., A. A. Baez, and A. Ovalle. [\"59 Bayesian Model for Comparative Assessment of Lactate and Procalcitonin using CURB 65 Risk Score as Predictor for ICU Admission.\"](https://www.annemergmed.com/article/S0196-0644(14)00691-X/fulltext) Annals of emergency medicine 64.4 (2014): S21-S22.\n\n[52] - Lim, W. S., et al. [\"Defining community acquired pneumonia severity on presentation to hospital: an international derivation and validation study.\"](https://www.ncbi.nlm.nih.gov/pubmed/12728155) Thorax 58.5 (2003): 377-382.\n\n[53] - [CURB-65 Score for Pneumonia Severity](https://www.mdcalc.com/curb-65-score-pneumonia-severity)\n\n[54] - 42.\tLu, Hsueh-Yi, et al. [\"Predicting rotator cuff tears using data mining and bayesian likelihood ratios.\"](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0094917) PloS one 9.4 (2014): e94917.","outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}